{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f49323-2a1c-47a6-bf1c-93bf50a58dbb",
   "metadata": {},
   "source": [
    "# An√°lise Explorat√≥ria de Dados - Missing Data - Censo Escolar 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222af818-7853-45aa-93c6-91739f2034e9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Liga√ß√£o com BD SQLite + carga de Dataframe desde o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc019cf-6a99-41e5-a80d-88251b181752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de colunas na RAW: 426\n",
      "Total de colunas na TRUSTED: 426\n",
      "Total de vari√°veis no DICION√ÅRIO: 476\n",
      "Total de vari√°veis √öNICAS no DICION√ÅRIO: 476\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ SUCESSO: Nenhuma vari√°vel duplicada encontrada no Dicion√°rio.\n",
      "--------------------------------------------------\n",
      "\n",
      "üö® ATEN√á√ÉO: 50 colunas est√£o no Dicion√°rio mas FALTAM na camada Trusted:\n",
      "['IN_AGUA_FILTRADA', 'IN_BANHEIRO_DENTRO_PREDIO', 'IN_BANHEIRO_FORA_PREDIO', 'IN_BAS', 'IN_BERCARIO', 'IN_BRASIL_ALFABETIZADO', 'IN_CONVENIADA_PP', 'IN_DEPENDENCIAS_PNE', 'IN_ENERGIA_GERADOR', 'IN_ENERGIA_OUTROS', 'IN_EQUIP_FAX', 'IN_EQUIP_FOTO', 'IN_EQUIP_RETROPROJETOR', 'IN_EQUIP_VIDEOCASSETE', 'IN_FINAL_SEMANA', 'IN_FORMACAO_ALTERNANCIA', 'IN_FUNDAMENTAL_CICLOS', 'IN_GRUPOS_NAO_SERIADOS', 'IN_LAVANDERIA', 'IN_LIXO_JOGA_OUTRA_AREA', 'IN_LIXO_OUTROS', 'IN_LIXO_RECICLA', 'IN_LOCAL_FUNC_CASA_PROFESSOR', 'IN_LOCAL_FUNC_SALAS_EMPRESA', 'IN_LOCAL_FUNC_TEMPLO_IGREJA', 'IN_MATERIAL_ESP_INDIGENA', 'IN_MATERIAL_ESP_NAO_UTILIZA', 'IN_MATERIAL_ESP_QUILOMBOLA', 'IN_MODULOS', 'IN_PERIODOS_SEMESTRAIS', 'IN_SERIE_ANO', 'IN_TIPO_ATEND_AC', 'IN_TIPO_ATEND_AEE', 'IN_TIPO_ATEND_ESCOLARIZACAO', 'QT_COMPUTADOR', 'QT_COMP_ADMINISTRATIVO', 'QT_COMP_ALUNO', 'QT_EQUIP_COPIADORA', 'QT_EQUIP_FAX', 'QT_EQUIP_FOTO', 'QT_EQUIP_IMPRESSORA', 'QT_EQUIP_IMPRESSORA_MULT', 'QT_EQUIP_PARABOLICA', 'QT_EQUIP_RETROPROJETOR', 'QT_EQUIP_VIDEOCASSETE', 'QT_FUNCIONARIOS', 'QT_MAT_EJA_FUND_AIAF', 'QT_MAT_EJA_FUND_PJ', 'QT_SALAS_EXISTENTES', 'TP_CONVENIO_PODER_PUBLICO']\n",
      "--------------------------------------------------\n",
      "\n",
      "‚úÖ SUCESSO: Todas as colunas da camada Trusted possuem uma defini√ß√£o no Dicion√°rio.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "\n",
    "# =================================================================\n",
    "# FASE 1: CONFIGURA√á√ÉO DOS CAMINHOS\n",
    "# =================================================================\n",
    "\n",
    "# Caminho para o arquivo RAW original\n",
    "RAW_CSV_PATH = \"/home/fcsr/Documentos/Dbeaver/qualidade_dados_censo_escolar_2024/data/1_raw/microdados_ed_basica_2024.csv\"\n",
    "\n",
    "# Caminho para o banco de dados SQLite\n",
    "DB_PATH = \"/home/fcsr/Documentos/Dbeaver/qualidade_dados_censo_escolar_2024/data/0_sqlite/censo_escolar\"\n",
    "\n",
    "# Nomes das tabelas no SQLite\n",
    "TABLE_TRUSTED = 'microdados_ed_basica_trusted'\n",
    "TABLE_DICIONARIO = 'dicionario'\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# FASE 2: CARGA DOS DADOS E EXTRA√á√ÉO DAS CHAVES\n",
    "# =================================================================\n",
    "\n",
    "# --- Carregar dados do SQLite (Trusted e Dicion√°rio) ---\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "df_trusted = pd.read_sql_query(f\"SELECT * FROM {TABLE_TRUSTED}\", conn)\n",
    "df_dicionario = pd.read_sql_query(f\"SELECT * FROM {TABLE_DICIONARIO}\", conn)\n",
    "conn.close()\n",
    "\n",
    "# --- Carregar apenas o cabe√ßalho do arquivo RAW para pegar as colunas ---\n",
    "# nrows=0 √© um truque para ler apenas o cabe√ßalho, sem carregar dados, o que √© muito r√°pido.\n",
    "df_raw = pd.read_csv(RAW_CSV_PATH, sep=';', nrows=0, low_memory=False, encoding='latin1')\n",
    "\n",
    "# --- Extrair as listas de colunas/vari√°veis como conjuntos (sets) para f√°cil compara√ß√£o ---\n",
    "colunas_raw = set(df_raw.columns)\n",
    "colunas_trusted = set(df_trusted.columns)\n",
    "variaveis_dicionario = set(df_dicionario['VARIAVEL'])\n",
    "\n",
    "print(f\"Total de colunas na RAW: {len(colunas_raw)}\")\n",
    "print(f\"Total de colunas na TRUSTED: {len(colunas_trusted)}\")\n",
    "print(f\"Total de vari√°veis no DICION√ÅRIO: {len(df_dicionario['VARIAVEL'])}\")\n",
    "print(f\"Total de vari√°veis √öNICAS no DICION√ÅRIO: {len(variaveis_dicionario)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "\n",
    "# =================================================================\n",
    "# FASE 3: DIAGN√ìSTICO E COMPARA√á√ÉO\n",
    "# =================================================================\n",
    "\n",
    "# --- 1. An√°lise de Duplicatas no Dicion√°rio ---\n",
    "if len(df_dicionario['VARIAVEL']) != len(variaveis_dicionario):\n",
    "    print(\"\\nüö® ATEN√á√ÉO: Foram encontradas vari√°veis duplicadas no Dicion√°rio!\")\n",
    "    duplicatas = df_dicionario[df_dicionario['VARIAVEL'].duplicated(keep=False)].sort_values('VARIAVEL')\n",
    "    print(\"Vari√°veis duplicadas:\")\n",
    "    display(duplicatas)\n",
    "else:\n",
    "    print(\"\\n‚úÖ SUCESSO: Nenhuma vari√°vel duplicada encontrada no Dicion√°rio.\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 2. Compara√ß√£o: Dicion√°rio vs. Trusted ---\n",
    "# Quais vari√°veis est√£o no dicion√°rio mas n√£o na tabela trusted?\n",
    "# Estas s√£o as colunas \"perdidas\" durante o ETL.\n",
    "colunas_perdidas = sorted(list(variaveis_dicionario - colunas_trusted))\n",
    "\n",
    "if colunas_perdidas:\n",
    "    print(f\"\\nüö® ATEN√á√ÉO: {len(colunas_perdidas)} colunas est√£o no Dicion√°rio mas FALTAM na camada Trusted:\")\n",
    "    print(colunas_perdidas)\n",
    "else:\n",
    "    print(\"\\n‚úÖ SUCESSO: Todas as vari√°veis do Dicion√°rio est√£o presentes na camada Trusted.\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# --- 3. Compara√ß√£o Extra: Trusted vs. Dicion√°rio ---\n",
    "# Existem colunas na trusted que n√£o t√™m defini√ß√£o no dicion√°rio?\n",
    "colunas_sem_definicao = sorted(list(colunas_trusted - variaveis_dicionario))\n",
    "\n",
    "if colunas_sem_definicao:\n",
    "    print(f\"\\nüö® ATEN√á√ÉO: {len(colunas_sem_definicao)} colunas est√£o na Trusted mas FALTAM no Dicion√°rio:\")\n",
    "    print(colunas_sem_definicao)\n",
    "else:\n",
    "    print(\"\\n‚úÖ SUCESSO: Todas as colunas da camada Trusted possuem uma defini√ß√£o no Dicion√°rio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30e576-cc28-4292-943d-2bc254c104f8",
   "metadata": {},
   "source": [
    "#### Conclus√£o de bloco:\n",
    "- Liga√ß√£o com SQLite, ok!\n",
    "- N√∫mero de colunas de RAW e TRUSTED checadas, ok!\n",
    "- As colunas de trusted constam no dicion√°rio, ok!\n",
    "- As 50 vari√°veis mencionadas como n√£o localizadas s√£o aquelas que foram coletadas apenas at√© o Censo Escolar de 2023 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932c1f2-26fb-4980-aaae-b21df2f33946",
   "metadata": {},
   "source": [
    "## Explora√ß√£o de Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255981eb-6f6f-40c3-b44b-bdb77a746fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames encontrados. Iniciando a an√°lise agregada...\n",
      "Reorganizando a tabela de dados (melt)...\n",
      "Juntando dados com as categorias do dicion√°rio...\n",
      "Agrupando e calculando as m√©tricas de qualidade...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =================================================================\n",
    "# FASE 0: PR√â-REQUISITO\n",
    "# =================================================================\n",
    "# Este script assume que os DataFrames 'df_trusted' e 'df_dicionario'\n",
    "# j√° foram carregados na mem√≥ria a partir do seu banco de dados SQLite.\n",
    "# Se precisar carreg√°-los novamente, use o script anterior.\n",
    "\n",
    "# Verifica√ß√£o para garantir que os DFs existem\n",
    "if 'df_trusted' not in locals() or 'df_dicionario' not in locals():\n",
    "    print(\"ERRO: Os DataFrames 'df_trusted' e 'df_dicionario' n√£o foram encontrados.\")\n",
    "    print(\"Por favor, execute o script de conex√£o com o SQLite primeiro.\")\n",
    "else:\n",
    "    print(\"DataFrames encontrados. Iniciando a an√°lise agregada...\")\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # FASE 1: UNPIVOT (MELT) DA TABELA TRUSTED\n",
    "    # =================================================================\n",
    "    # Transformamos a tabela de formato 'largo' para 'longo'.\n",
    "    # Cada linha agora representar√° uma √∫nica c√©lula da tabela original.\n",
    "    print(\"Reorganizando a tabela de dados (melt)...\")\n",
    "    df_long = df_trusted.melt(var_name='VARIAVEL', value_name='VALOR')\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # FASE 2: JOIN COM O DICION√ÅRIO\n",
    "    # =================================================================\n",
    "    # Juntamos a tabela longa com as informa√ß√µes de categoria do dicion√°rio.\n",
    "    print(\"Juntando dados com as categorias do dicion√°rio...\")\n",
    "    df_dict_subset = df_dicionario[['VARIAVEL', 'GRUPO_CAT', 'SUB_GRUPO_CAT']].drop_duplicates()\n",
    "    df_merged = pd.merge(df_long, df_dict_subset, on='VARIAVEL', how='left')\n",
    "    \n",
    "    # Preenche categorias para vari√°veis que n√£o foram encontradas no dicion√°rio\n",
    "    df_merged['GRUPO_CAT'] = df_merged['GRUPO_CAT'].fillna('Sem Grupo')\n",
    "    df_merged['SUB_GRUPO_CAT'] = df_merged['SUB_GRUPO_CAT'].fillna('Sem Subgrupo')\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # FASE 3: AGRUPAMENTO E C√ÅLCULO DAS M√âTRICAS\n",
    "    # =================================================================\n",
    "    print(\"Agrupando e calculando as m√©tricas de qualidade...\")\n",
    "    \n",
    "    # Agrupamos por categoria e agregamos os resultados\n",
    "    # 'size' conta o total de c√©lulas no grupo (incluindo nulos)\n",
    "    # As lambdas contam os nulos e os placeholders (-100)\n",
    "    df_grouped = df_merged.groupby(['GRUPO_CAT', 'SUB_GRUPO_CAT']).agg(\n",
    "        total_celulas=('VALOR', 'size'),\n",
    "        contagem_nulos=('VALOR', lambda x: x.isnull().sum()),\n",
    "        contagem_placeholder=('VALOR', lambda x: (x == -100).sum())\n",
    "    )\n",
    "\n",
    "    # C√°lculo das porcentagens\n",
    "    total_missing = df_grouped['contagem_nulos'] + df_grouped['contagem_placeholder']\n",
    "    df_grouped['%_de_Missing_Data'] = (total_missing / df_grouped['total_celulas']) * 100\n",
    "    df_grouped['%_Preenchido'] = 100 - df_grouped['%_de_Missing_Data']\n",
    "    \n",
    "    # Adicionando o total de registros (n√∫mero de linhas da tabela original)\n",
    "    df_grouped['Total_de_Registros'] = len(df_trusted)\n",
    "\n",
    "\n",
    "    # =================================================================\n",
    "    # FASE 4: FORMATA√á√ÉO E APRESENTA√á√ÉO FINAL\n",
    "    # =================================================================\n",
    "    print(\"Formatando o relat√≥rio final...\")\n",
    "\n",
    "    # Selecionando e renomeando as colunas para o resultado final\n",
    "    df_resultado = df_grouped[[\n",
    "        'Total_de_Registros',\n",
    "        '%_de_Missing_Data',\n",
    "        '%_Preenchido'\n",
    "    ]].copy()\n",
    "\n",
    "    # Ordenando pelo % de Missing Data, do maior para o menor\n",
    "    df_resultado = df_resultado.sort_values(by='%_de_Missing_Data', ascending=False)\n",
    "    \n",
    "    # Formatando as porcentagens para melhor visualiza√ß√£o\n",
    "    df_resultado['%_de_Missing_Data'] = df_resultado['%_de_Missing_Data'].map('{:.2f}%'.format)\n",
    "    df_resultado['%_Preenchido'] = df_resultado['%_Preenchido'].map('{:.2f}%'.format)\n",
    "    \n",
    "    # Trazendo os grupos de volta como colunas\n",
    "    df_resultado = df_resultado.reset_index()\n",
    "\n",
    "    print(\"\\n--- Relat√≥rio de Qualidade de Dados por Categoria ---\")\n",
    "    display(df_resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
